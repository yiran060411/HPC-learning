# Lecture-1笔记

# 并行程序设计实践 - 暑期课程笔记

## 1. 课程介绍

- **讲师**: 介绍并行算法设计和实现的基本方法
- **学生**: 设计和实现并行算法来解决一些简单的问题
- **目标**:
    - 对并行计算的基本概念有很好的理解
    - 为今后深入学习并行计算理论及其应用打下坚实的基础

## 2. 并行计算

- **定义**: 使用并行计算机（如多核计算机、计算机集群或其他先进的并行/分布式计算系统）高速解决高级计算问题
- **性能指标**: 通常以每秒浮点运算次数（FLOPS）衡量
    - Giga FLOPS (10^9 FLOPS)
    - Tera FLOPS (10^12 FLOPS)
    - Peta FLOPS (10^15 FLOPS)
    - Exa FLOPS (10^18 FLOPS)
- **理论峰值FLOPS计算公式**:
    - `FLOPS = 核心数 × 时钟频率 × 每个时钟周期的浮点操作数`

### 2.1 为什么需要并行计算？

- **技术推动**: 如今的笔记本电脑甚至手机都是并行计算机
- **应用驱动**: 许多现代应用，如大数据分析、人工智能和深度学习，都严重依赖并行计算

### 2.2 并行计算的挑战

- 如何将一个大任务分解成多个小任务？
- 如何将任务分配给进程/线程？
- 如果进程/线程需要共享部分结果怎么办？
- 并行程序的性能如何？
- **频率墙 (Frequency Wall)**: 增加频率和更深的流水线在性能上的回报已经减少
- **功耗墙 (Power Wall)**: 如果芯片运行速度更快（更高的时钟频率），芯片将会融化
- **指令级并行墙 (ILP Wall)**: 寻找更多ILP的回报正在减少
- 摩尔定律依然有效，但不能通过显著提高频率来提高性能

### 2.3 多核技术

- 功耗 ∝ 电压^2 × 频率 （P ∝ V^2 * F）
- 频率 ∝ 电压 （F ∝ V）
- 功耗 ∝ 频率^3 （P ∝ F^3）
- 单核情况下，频率提高50%，性能提高1.5倍，但功耗提高3.3倍
- 使用双核，为了提高相同的峰值性能，可以将频率降低25%，从而将功耗降低到0.8倍

### 2.4 并行计算的应用

- **科学**: 风暴预测和气候预测、理解生物体的生化过程
- **工程**: 计算流体动力学和飞机设计、地震和结构建模、分子纳米技术
- **商业**: 计算金融
- **大数据 (Data Analytics)**: 将原始数据转化为有意义的信息，需要大量的计算能力，需要使用并行和分布式计算策略。例如MapReduce等高级编程模型。
- **深度学习 (Deep Learning)**: 通过分析大量数据进行训练，实现分类和预测。主要归功于可用训练数据量的增加和更强大的计算资源，这使我们能够训练更大、更深的神经网络。

## 3. 并行计算机组织

- **多核 (Multicore)**:
    - 多个核心共享内存
    - 小规模（高端~100个核心）
- **集群 (Cluster)**:
    - 多个处理单元 (PE)，独立的计算机，具有多核和/或GPU，通过互连网络连接
    - 大规模，几乎所有超级计算机都是集群
- **GPU**:
    - 附加的加速器 - 最初设计用于图形处理
    - 现在可以用作一种更通用的GPU，用于具有规则计算和数据模式的应用，特别是对于机器学习

### 3.1 多核

- 所有电脑现在都是多核电脑系统
    - 多个处理器或核心
    - 片上缓存
    - 共享全局内存空间（外部缓存和DRAM）

### 3.2 计算机集群

- 多个独立的计算机通过互连网络连接
- 每个独立的计算机都是一个具有自己本地内存的多核系统
- 大多数超级计算机都是一种计算机集群
- 每个计算节点不仅包含多个核心，还包含GPU
    - 例如，目前世界上最快的超级计算机“Frontier”由9472个计算节点组成，每个节点都有一个64核的CPU和四个GPU

### 3.3 现代GPU

- 每个GPU包含
    - 多个SM（流式多处理器）
        - 多个SP（流式处理器，也称为“标量处理器核心”或“线程处理器”）
        - 寄存器文件
        - 共享内存
    - 常量缓存（SM只读）
    - 纹理缓存（SM只读）
    - 设备内存
- 新一代GPU，例如GeForce RTX 4090
    - 每个流式多处理器 (SM)
        - 128 个核心（流式处理器或 SP）
        - 16MB 共享内存
        - 32MB 寄存器文件
        - 4 个用于机器学习的张量核心
    - 该芯片有 128 个 SM，即 16,384 个内核、512 个张量内核以及 72MB L2 缓存

## 4. 互连网络

- 互连网络是计算机系统中最重要的组件之一，它对应用程序的性能有重大影响，尤其是在大型计算系统中
- **静态网络**: 消息必须沿着已建立的链接路由
    - 这意味着单个消息必须通过中间处理器才能到达其目的地
- **动态网络**: 在消息沿着链路和交换机路由时，动态网络会动态地在两个或多个节点之间建立连接
- **完全连接网络**: 每个处理器都连接到其他每个处理器。链接数量扩展性不好。
- **Crossbar**: 交换网络的成本随着处理器数量的增加而增长，扩展性不好。
- **Frontier**: 是世界上第一台百亿亿次超级计算机 (10^18 FLOPS)
    - 使用 9,472 个计算节点
    - 每个节点包含一个 64 核 CPU 和 4 个 GPU（总共 606,208 个内核和 37,888 个 GPU）
    - 计算节点使用最先进的 Slingshot 网络互连
    - Slingshot 互连网络的核心是 Rosetta 交换机
    - 默认拓扑是 Dragonfly——一种分层直接拓扑

### 4.1 Rosetta交换机

- Rosetta 交换机具有 64 个端口，速率为 200 Gb/s，可连接计算节点或其他交换机以形成不同的互连网络
- 端口分为 32 个 Tile，每个 Tile 2 个端口
- Tile 排列为 4 行，每行 8 个 Tile
- 同一行上的 Tile 通过 16 条按行总线连接
- 行总线用于将数据从相应的端口发送到该行上的其他端口
- 同一列上的 Tile 通过 Tile 间 Crossbar 连接
- Tile 间 Crossbar 具有来自该行上 16 个端口的 16 个输入和到该列上 8 个端口的 8 个输出
- 从一个端口到另一个端口最多需要 2 跳（直径 = 2）

### 4.2 Dragonfly拓扑

- Dragonfly 是一种分层直接拓扑
    - 交换机被组织成组
    - 在每个组中，交换机使用电链路（铜缆）以完全（或完成）连接的图形连接
    - 组也以完全连接的图形连接，但使用光链路（光缆）
- 优点
    - 低延迟：由于组内和组间都完全连接，因此 Dragonfly 的直径为 3 个交换机到交换机的跃点
    - 低成本：与其他大型系统拓扑相比，最大限度地减少了长光缆
    - 高度模块化和可扩展

## 5. 计算机分类

- **Flynn分类法**: Prof Michael Flynn (Stanford University) 在 60 年代提出的计算机分类方法
    - **SISD (Single Instruction Single Data)**: 单指令单数据流, 单处理器
    - **SIMD (Single Instruction Multiple Data)**: 单指令多数据流, 处理器阵列，流水线向量处理器
    - **MISD (Multiple Instruction Single Data)**: 多指令单数据流, 很少使用
    - **MIMD (Multiple Instruction Multiple Data)**: 多指令多数据流, 多处理器，多计算机
- **物理组织**
    - **共享内存机器 (MIMD)**: 例如，具有共享内存的多核处理器。小规模，高端单节点计算服务器只包含几十个核心。
    - **分布式内存机器 (MIMD)**: 多个计算节点，每个节点都有自己的本地内存。高度可扩展，所有超级计算机都是分布式内存机器。
    - **加速器**: SIMD（单指令多数据）用于数据并行计算，例如 GPU、TPU。
    - 大规模现代并行计算机是上述的组合，例如，计算机集群由多个具有分布式内存的计算节点组成，并且每个节点包含多个具有共享内存的核心，并且还可能包含一个甚至多个加速器。

## 6. 并行编程模型

- **逻辑组织**
    - （或并行计算平台）——提供了一种思考并行程序组织的方式
- **基于分类，我们有三个并行计算平台**:
    - 共享内存
    - 分布式内存
    - SIMD（数据并行）和多线程
- **本课程将讨论如何使用以下平台进行编程**:
    - 使用 OpenMP 的共享内存平台
    - 使用 MPI 的分布式内存平台
    - 还将简要讨论用于 GPU 的 CUDA 编程，但没有练习

## 7. 实验练习

- 熟悉 EduCoder (头歌平台)
- 编译并运行两个 "Hello World!" 程序
    - `omp_hw.c`
        - 编译: `gcc –fopenmp –o omp_hw omp_hw.c`
        - 运行: `./omp_hw`
    - `mpi_hw.c`
        - 编译: `mpicc –o mpi_hw mpi_hw.c`
        - 运行: `mpirun –np x mpi_hw`
            - `x` 是一个整数，表示将创建多少个进程
            - 可以多次运行程序，使用不同的 `x` 值

## 8. 词汇表

- **并行计算**: 是一种计算方法，它将一个大的计算问题分解成多个可以同时执行的小问题。
- **FLOPS (Floating-point Operations Per Second)**: 每秒浮点运算次数，是衡量计算机性能的指标。
- **多核处理器**: 在单个芯片上集成了多个处理器核心的处理器。
- **计算机集群**: 由多台计算机通过网络连接而成，作为一个整体来解决计算问题。
- **GPU (Graphics Processing Unit)**: 图形处理器，最初用于图形渲染，现在也被广泛用于通用计算。
- **CUDA**: NVIDIA开发的并行计算平台和编程模型，用于在GPU上进行通用计算。
- **OpenMP**: 一种用于共享内存并行系统的编程接口。
- **MPI (Message Passing Interface)**: 消息传递接口，一种用于分布式内存并行系统的通信协议。
- **SIMD (Single Instruction, Multiple Data)**: 单指令多数据流，一种并行计算架构，其中一个指令同时操作多个数据。
- **MIMD (Multiple Instruction, Multiple Data)**: 多指令多数据流，一种并行计算架构，其中多个处理器同时执行不同的指令，操作不同的数据。