# lecture笔记-3

# **悉尼大学计算机科学学习笔记：并行编程与算法设计**

# **引言 / 课程概述**

随着计算需求的日益增长，单核处理器的性能提升已遭遇瓶颈，并行计算已成为推动科学研究和工业应用发展的核心驱动力。本课程及笔记旨在引导学习者进入并行计算的世界，理解其基本原理，掌握核心设计方法，并能将其应用于实际问题解决中。

# **1. 并行计算性能度量**

### **1.1 加速比（Speedup）**

**定义**：加速比是衡量并行算法相对于顺序算法性能提升的度量，定义为：

```

S = T₁ / Tₚ
```

其中：

- T₁：最优顺序算法在单个处理器上的执行时间
- Tₚ：并行算法在 p 个处理器上的执行时间

**加速比类型**：

- 绝对加速比：使用最优顺序算法与并行算法比较
- 相对加速比：使用相同算法的顺序版本与并行版本比较

**理想情况**：在 p 个处理器上运行时，理想加速比为 p（线性加速比）

### **1.2 效率（Efficiency）**

**定义**：效率衡量了在并行计算中有效利用的处理器比例，定义为：

```

E = S / p = T₁ / (p × Tₚ)
```

**效率特点**：

- 理想效率为 1（100%），表示所有处理器都在执行有用工作
- 实际效率通常低于 1，受多种因素影响：
    - 处理器间通信开销
    - 负载不均衡
    - 算法固有的顺序部分
    - 资源竞争
    - 同步开销

### **1.3 Amdahl 定律**

**背景**：由 Gene Amdahl 于 1967 年提出，用于预测并行系统的理论最大加速比

**定义**：如果程序中有比例为 f 的部分无法并行化（必须顺序执行），则使用 p 个处理器的理论加速比为：

```

S = 1 / (f + (1-f)/p)
```

**Amdahl 定律的关键启示**：

- 当处理器数 p 趋于无穷大时，最大加速比为 1/f
- 程序中的顺序部分是并行性能的主要瓶颈
- 即使有无限多的处理器，固有的顺序部分也会限制可达到的最大加速比

**示例**：若程序有 5% 的顺序部分，则最大理论加速比为 20 倍，无论使用多少处理器

### **1.4 Gustafson 定律（Gustafson-Barsis 定律）**

**背景**：由 John L. Gustafson 和 Edwin H. Barsis 于 1988 年提出，作为 Amdahl 定律的补充

**核心思想**：随着处理器数量增加，我们往往会解决更大规模的问题，而不是解决相同规模的问题

**定义**：

```

S(p) = p - α × (p - 1)
```

其中，α 是顺序部分在并行环境中的执行时间与总执行时间之比

**Gustafson 定律的关键启示**：

- 问题规模可随处理器数量扩展
- 对于可扩展问题，加速比可以接近于处理器数量
- 强调了并行计算在解决大规模问题上的优势

# **2. 并行算法设计方法论**

### **2.1 并行算法设计的两个主要阶段**

并行算法设计通常分为两个主要阶段：机器无关阶段和机器相关阶段。这种划分有助于系统性地设计出高效、可移植的并行算法。

### **2.1.1 机器无关阶段（Machine-Independent Phase）**

**任务分解（Task Decomposition）**：

- 将计算问题分解为可并行执行的多个任务
- 识别潜在的并行性，不考虑具体硬件限制
- 主要方法：
    - **数据分解**：将数据划分为多个子集，各子集上的操作可并行执行
    - **功能分解**：将计算过程分解为多个功能上独立的任务

**通信与同步（Communication & Synchronization）**：

- 确定分解后的任务之间的数据依赖关系
- 识别需要进行通信或同步的点
- 设计通信模式和通信内容
- 尽量减少通信频率和数据量

### **2.1.2 机器相关阶段（Machine-Dependent Phase）**

**任务分配（Task Assignment）**：

- 将分解的任务映射到具体的处理器上
- 考虑处理器拓扑和通信成本
- 目标：最小化处理器间通信开销

**负载均衡（Load Balancing）**：

- 使各处理器的工作负载尽可能均匀
- 避免部分处理器空闲等待
- 考虑动态负载均衡机制应对不可预测的工作量变化
- 平衡计算负载与通信开销

### **2.2 任务依赖图（Task Dependency Graph）**

任务依赖图是并行算法设计中的重要工具，用于可视化表示任务之间的依赖关系。

**定义**：

- 有向图 G = (V, E)，其中顶点 V 表示任务，边 E 表示依赖关系
- 如果存在从任务 A 到任务 B 的边，表示 B 依赖于 A（B 必须在 A 完成后才能开始）

**应用**：

- 识别可以并行执行的任务（无依赖关系的任务）
- 分析关键路径（决定执行总时间的最长路径）
- 辅助任务调度决策
- 优化并行执行策略

**示例**：矩阵乘法中的任务依赖图可以清晰地展示各计算单元之间的依赖关系，有助于设计高效的并行算法。

### **2.3 提高并行性的代数优化：结合律的应用**

许多数学运算（如加法、乘法）满足结合律，即 (a ⊕ b) ⊕ c = a ⊕ (b ⊕ c)。这一特性可用于重构计算以提高并行性。

**结合律在并行计算中的应用**：

- 允许重组计算顺序，创造更多分解为可并行求解的子问题
- 减少计算的关键路并行机会
- 实现"分治"策略：将大问题径长度

**典型应用场景**：

- 向量内积计算
- 矩阵乘法
- 前缀和计算
- 归约操作（如求和、求最大/最小值）

**示例**：求和操作的并行化

- 顺序求和：T₁ = n - 1 步
- 使用二叉树结构的并行求和：T_parallel = log₂ n 步
- 通过重组计算顺序，显著减少了计算的关键路径长度

# **3. 高斯消元法与数值稳定性**

### **3.1 高斯消元法基础**

高斯消元法是求解线性方程组的经典方法，也是许多数值计算问题的基础。

**算法概述**：

1. 前向消元阶段：将增广矩阵变换为行阶梯形矩阵
2. 回代阶段：从最后一个方程开始，依次求解各个未知数

**基本步骤**：

- 将第一个方程的第一个系数变为 1
- 用第一个方程消除其余方程中的第一个变量
- 对剩余的子矩阵重复上述过程
- 完成前向消元后进行回代计算

### **3.2 数值稳定性问题**

在实际计算中，由于浮点数表示的精度限制，高斯消元法可能面临数值稳定性问题。

**主要挑战**：

- 主元（pivot）过小或为零导致的除法不稳定
- 舍入误差的累积和放大
- 计算过程中的条件数恶化

**数值不稳定的后果**：

- 计算结果严重失准
- 算法可能无法继续执行
- 解的精度显著降低

### **3.3 部分选主法（Partial Pivoting）**

为解决数值稳定性问题，常采用部分选主法进行改进。

**基本思想**：

- 在每一步消元前，选择当前列中绝对值最大的元素作为主元
- 通过行交换操作，将该元素移至对角线位置

**部分选主的优势**：

- 避免除以极小值导致的数值不稳定
- 减小消元过程中的舍入误差累积
- 提高算法的数值稳定性，确保计算精度

**实现细节**：

- 在每次消元前，搜索当前列从对角线元素到最后一行中的最大值
- 如果最大值不在对角线位置，则交换相应行
- 使用缩放后的最大元素作为主元进行消元

### **3.4 高斯消元法的并行实现**

高斯消元法具有一定的并行潜力，可设计并行算法提高计算效率。

**并行化策略**：

- 矩阵分块：按行或列将矩阵分配给不同处理器
- 流水线并行：不同消元步骤的重叠执行
- 并行回代：适当条件下可并行计算未知数

**并行实现的挑战**：

- 部分选主过程中的数据依赖
- 处理器间的通信开销
- 负载均衡问题，特别是在异构计算环境中

# **4. 专业术语表**

| **术语** | **中文翻译** | **解释** |
| --- | --- | --- |
| Speedup | 加速比 | 顺序算法与并行算法执行时间的比值，衡量并行化带来的性能提升 |
| Efficiency | 效率 | 加速比除以处理器数，衡量处理器资源的利用率 |
| Amdahl's Law | 阿姆达尔定律 | 描述并行计算中固有顺序部分对最大可能加速比的限制 |
| Gustafson's Law | 古斯塔夫森定律 | 描述问题规模扩展情况下的并行加速比 |
| Task Decomposition | 任务分解 | 将计算问题分解为可并行执行的多个子任务 |
| Load Balancing | 负载均衡 | 使各处理器的工作负载尽可能均匀分布 |
| Task Dependency Graph | 任务依赖图 | 可视化表示任务之间依赖关系的有向图 |
| Associative Law | 结合律 | 运算顺序改变不影响结果的代数性质，常用于并行优化 |
| Gaussian Elimination | 高斯消元法 | 求解线性方程组的经典方法 |
| Partial Pivoting | 部分选主法 | 高斯消元中选择当前列最大值作为主元以提高数值稳定性 |
| Critical Path | 关键路径 | 任务依赖图中最长的路径，决定了并行执行的最短时间 |
| Machine-Independent | 机器无关 | 不依赖于特定硬件架构的并行算法设计阶段 |
| Machine-Dependent | 机器相关 | 考虑具体硬件特性的并行算法设计阶段 |
| Synchronization | 同步 | 确保并行任务按正确顺序执行的机制 |
| Communication Overhead | 通信开销 | 并行计算中处理器间数据交换导致的额外时间消耗 |

# **5. 总结与关键要点**

- **并行性能度量**：加速比和效率是评估并行算法性能的关键指标
- **Amdahl 定律**：揭示了程序中顺序部分对并行性能的根本限制
- **并行算法设计**：应遵循机器无关和机器相关两个阶段，系统性地设计并行算法
- **任务依赖图**：是理解和优化并行任务结构的重要工具
- **代数优化**：利用运算的结合律等性质可以重构计算以提高并行性
- **高斯消元法**：求解线性方程组的经典方法，结合部分选主可提高数值稳定性
- **并行计算的权衡**：在设计并行算法时，需要平衡任务粒度、通信开销和负载均衡

# 6. 并行编程核心概念解析

并行编程旨在通过同时使用多个计算资源来解决问题，以提高计算速度和效率。理解并行程序的性能需要掌握几个关键概念：加速比、效率和 Amdahl 定律。

1. **加速比 (Speedup)**
    - **中文解释:** 加速比衡量了并行算法相对于最优串行算法的性能提升程度。简单来说，就是同一个任务，用单个处理器完成所需的时间与用多个处理器并行完成所需时间之比。
    - **定义:** 如果 $T_s$ 是最优串行算法在单个处理器上的执行时间，而 $T_p$ 是并行算法在使用 $P$ 个处理器时的执行时间，那么加速比 $S$ 定义为：
    $S = T_s / T_p$
    - **意义:** 加速比越大，表示并行化带来的性能提升越显著。理论上，使用 $P$ 个处理器时，最大加速比可以达到 $P$。
2. **效率 (Efficiency)**
    - **中文解释:** 效率衡量了并行计算中处理器资源的有效利用程度。它反映了并行化带来的加速比与所使用的处理器数量之间的关系。
    - **定义:** 效率 $E$ 定义为加速比 $S$ 除以使用的处理器数量 $P$：
    $E = S / P$
    - **意义:** 效率的取值范围通常在 0 到 1 之间（或 0% 到 100%）。效率越高，说明每个处理器在并行计算中做“有用功”的比例越高，通信、同步等开销相对越小。理想情况下，效率为 1（或 100%），意味着加速比等于处理器数量。
3. **Amdahl 定律 (Amdahl's Law)**
    - **中文解释:** Amdahl 定律是并行计算领域一个非常著名的定律，由 Gene Amdahl 在 1967 年提出。它预测了在固定问题规模下，使用多个处理器并行计算所能达到的理论最大加速比。该定律强调了程序中不可并行执行的串行部分对整体加速比的限制。
    - **核心思想:** 任何程序都包含一部分可以并行执行的任务和一部分只能串行执行的任务。即使将可并行部分无限加速，整体程序的执行时间仍然受限于串行部分的执行时间。
    - **公式:** 假设程序中串行部分占总执行时间的比例为 $f$（则可并行部分占 $1-f$），使用 $P$ 个处理器进行并行计算，理论加速比 $S$ 为：
    $S = 1 / (f + (1-f)/P)$
    - **意义:** Amdahl 定律揭示了并行计算的局限性。即使处理器数量 $P$ 趋近于无穷大，加速比的上限也只能达到 $1/f$。这意味着如果程序中串行部分比例 $f$ 较大，无论增加多少处理器，加速比的提升都会非常有限。例如，如果程序有 10% 的串行部分 ($f=0.1$)，即使使用无限多的处理器，最大加速比也只能达到 $1/0.1 = 10$ 倍。

### 并行算法设计过程

设计一个高效的并行算法通常是一个系统性的过程，旨在充分挖掘问题的并行性并最小化并行开销。一个常用的设计方法是 PCAM 模型，它将设计过程分为四个阶段，通常可以归类为机器无关和机器相关两个主要阶段。

1. **机器无关阶段 (Machine-Independent Phase)**
    - **中文解释:** 这个阶段关注于问题的内在并行性，与具体的并行计算机体系结构无关。目标是将问题分解成可以并行执行的独立任务，并识别任务之间的依赖关系和数据交换需求。
    - **包含步骤 (PCAM 模型的前两个阶段):**
        - **划分 (Partitioning):** 将计算任务和/或数据分解成许多小块（细粒度任务）。这个阶段的目的是尽可能地暴露问题的并行性，分解得越细，潜在的并行度越高。划分可以分为**域分解 (Domain Decomposition)**（分解数据）和**功能分解 (Functional Decomposition)**（分解任务）。
        - **通信 (Communication):** 识别在划分阶段产生的任务之间需要进行的数据交换和同步操作。任务之间可能需要共享数据或等待其他任务完成。这个阶段需要确定哪些数据需要在任务之间传递，以及何时进行传递。
2. **机器相关阶段 (Machine-Dependent Phase)**
    - **中文解释:** 这个阶段考虑目标并行计算机的体系结构特性，如处理器数量、内存组织、通信网络等。目标是将机器无关阶段确定的任务有效地映射到具体的处理器上，以优化性能。
    - **包含步骤 (PCAM 模型的后两个阶段):**
        - **组合 (Agglomeration):** 将划分阶段产生的细粒度任务组合成更大的、粗粒度的任务。这样做的目的是为了减少任务数量，从而降低通信和同步的开销，并提高数据局部性。组合需要权衡并行性（细粒度有利）和通信开销（粗粒度有利）。
        - **映射 (Mapping):** 将组合后的任务分配给具体的处理器执行。目标是实现负载均衡（使各个处理器的工作量大致相等）并最小化通信开销。映射策略需要考虑处理器的拓扑结构和任务之间的通信模式。

### 任务依赖图与数学结合律的应用

在并行算法设计中，理解任务之间的关系以及利用数学性质是提高并行性的重要手段。

1. **任务依赖图 (Task Dependency Graph)**
    - **中文解释:** 任务依赖图是一种有向图，用于可视化表示并行程序中各个任务之间的依赖关系。图中的节点代表计算任务，有向边表示任务之间的依赖关系，即箭头的起点任务必须在箭头的终点任务开始之前完成。
    - **应用:**
        - **识别并行性:** 通过任务依赖图，可以清晰地看到哪些任务之间没有依赖关系，因此可以并行执行。
        - **确定执行顺序:** 图的拓扑结构决定了任务的合法执行顺序。没有前驱依赖的任务可以优先执行。
        - **调度:** 任务依赖图是并行任务调度的基础，调度器根据依赖关系安排任务在不同处理器上的执行。通常，任务依赖图是一个有向无环图 (DAG)。
2. **数学结合律 (Associative Law) 在并行算法中的应用**
    - **中文解释:** 结合律是数学中二元运算的一个性质，指在包含多个相同可结合运算的表达式中，运算的顺序不会影响结果。例如，加法和乘法满足结合律：$(a+b)+c = a+(b+c)$ 和 $(a \times b) \times c = a \times (b \times c)$。
    - **应用:** 在并行计算中，如果一个计算任务涉及对一组数据进行满足结合律的运算（如求和、求积、最大值、最小值等），那么这个运算可以被分解成多个子任务在不同处理器上并行执行，然后将子结果合并。例如，计算一组数的总和，可以将这组数分成几部分，每个处理器计算一部分的和，最后将这些部分的和相加得到总和。由于加法满足结合律，这种并行计算方式的结果与串行计算相同，且可以显著提高效率（这是一种典型的并行归约 Reduction 算法）。不满足结合律的运算（如浮点数加法在严格意义上不完全满足结合律，以及减法和除法）则难以直接进行简单的并行化。

### 高斯消元法及部分选主法

高斯消元法是一种求解线性方程组的经典方法，在数值计算中广泛应用。为了提高其数值稳定性和适用性，常常结合选主元策略，其中部分选主法是一种常用的改进方法。

1. **高斯消元法 (Gaussian Elimination)**
    - **中文解释:** 高斯消元法是一种用于求解线性方程组、计算矩阵的秩以及求逆矩阵的算法。其基本思想是通过一系列初等行变换（交换两行、某一行乘以非零常数、将某一行的一个倍数加到另一行）将线性方程组的增广矩阵转化为行阶梯形矩阵（或简化行阶梯形矩阵），然后通过回代过程求解未知数。
    - **过程:** 通常包括两个阶段：
        - **前向消元:** 通过初等行变换将矩阵转化为上三角形式。
        - **回代:** 从最后一个方程开始，逐个求解未知数。
    - **问题:** 在前向消元过程中，需要选择一个“主元”（pivot）来消除该列下方元素。如果主元为零或非常接近零，可能导致除以零或产生较大的舍入误差，影响计算结果的准确性（数值稳定性差）。
2. **部分选主法 (Partial Pivoting)**
    - **中文解释:** 部分选主法是高斯消元法中一种常用的选主元策略，旨在提高算法的数值稳定性。在进行每一列的消元之前，它会在当前列中（从当前主元位置到最底行）选择绝对值最大的元素作为主元，然后将该元素所在的行与当前主元行进行交换。
    - **目的:**
        - **避免除以零:** 确保选定的主元不为零。
        - **减小舍入误差:** 选择绝对值最大的元素作为主元可以最大程度地减小在消元过程中产生的乘数（即用于消除元素的倍数）的绝对值，从而抑制舍入误差的增长，提高计算的准确性。
    - **与全选主法比较:** 全选主法是在未被处理的子矩阵中的所有元素中选择绝对值最大的作为主元，并进行行和列的交换。全选主法在理论上数值稳定性最好，但寻找主元的工作量更大。部分选主法在数值稳定性和计算量之间取得了较好的平衡，因此在实际应用中更为普遍。

通过以上解释，希望能帮助您理解并行编程中的这些核心概念及其在算法设计和数值计算中的应用。